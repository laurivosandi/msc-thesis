\RequirePackage{ifpdf}
\documentclass[a4paper,11pt]{kth-mag}
\let\newfloat\undefined
\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage[english]{babel}
\usepackage{modifications}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage[numbers, square]{natbib}
\bibliographystyle{IEEEtranN}
\usepackage{color}
\usepackage[pdfusetitle,pdftex,colorlinks]{hyperref}
\hypersetup{pdfborder={0 0 0}}
\hypersetup{bookmarksdepth=3}
\hypersetup{bookmarksopen=true}
\hypersetup{bookmarksopenlevel=1}
\hypersetup{bookmarksnumbered=true}
\hypersetup{colorlinks=false}
\usepackage[toc,acronym]{glossaries}

%% Listings
\usepackage{listings}
\lstset{numbers=left, numberstyle=\scriptsize, firstnumber=1}
\lstset{basicstyle=\footnotesize\ttfamily,breaklines=true}
\lstset{keywordstyle=\color{teal}\bfseries}

%% Other
\usepackage{enumerate}
\usepackage{paralist}
\usepackage{relsize}

\hyphenation{Butterknife}

\title{Efficient and Reliable Filesystem Snapshot Distribution}

\subtitle{}
\author{Lauri Võsandi}
\date{}
\blurb{Master of Science Thesis in\\ Information and Communication Technology\\ Supervisor: Lars Kroll \\Examiner: Dr. Jim Dowling \\ Stockholm, Sweden, June 2015}
\trita{TRITA-ICT-EX-2015:???}

\makeglossaries

\begin{document}
\newacronym{acid}{ACID}{atomicity, consistency, isolation and durability properties}
\newacronym{api}{API}{application programming interface}
\newacronym{dht}{DHT}{distributed hash table}
\newacronym{dsl}{DSL}{domain specific language}
\newacronym{fai}{FAI}{Fully Automated Installation}
\newacronym{lxc}{LXC}{Linux Containers}
\newacronym{lvm}{LVM}{Logical Volume Management}
\newacronym{hdd}{HDD}{hard disk drive}
\newacronym{sdd}{SDD}{solid state disk}
\newacronym{nic}{NIC}{network interface card}
\newacronym{p2p}{P2P}{peer-to-peer}
\newacronym{pxe}{PXE}{Preboot eXecution Environment}
\newacronym{smb}{SMB}{Server Message Block}
\newacronym{cifs}{CIFS}{Common Internet Filesystem}
\newacronym{raid}{RAID}{Redundant Array of Independent Disks}
\newacronym{s3}{S3}{simple storage service}
\newacronym{sics}{SICS}{Swedish Institute of Computer Science}
\newacronym{sla}{SLA}{service level agreement}
\newacronym{ssd}{SSD}{solid state disk}
\newacronym{mbr}{MBR}{Master Boot Record}
\newacronym{tcp}{TCP}{transmission control protocol}
\newacronym{grub}{GRUB}{GRand Unified Bootloader}
\newacronym{ovf}{OVF}{Open Virtualization Format}
\newacronym{ova}{OVA}{Open Virtual Appliance}
\newacronym{zfs}{ZFS}{Zettabyte Filesystem}
\newacronym{http}{HTTP}{Hypertext Transport Protocol}
\newacronym{nfs}{NFS}{Network File System}
\newacronym{crc32c}{CRC-32C}{Cyclic Redundancy Check (Castagnoli)}
\newacronym{sha1}{SHA-1}{Secure Hash Algorithm}
\newacronym{ssh}{SSH}{Secure Shell}
\newacronym{tls}{TLS}{Transport Layer Security}
\newacronym{btrfs}{Btrfs}{B-tree file system}
\newacronym{ext4}{Ext4}{Fourth Extended Filesystem}
\newacronym{ntfs}{NTFS}{New Technology File System}
\newacronym{soc}{SoC}{System on a Chip}

\frontmatter
\pagestyle{empty}
\removepagenumbers
\maketitle
\selectlanguage{english}

%
%
% ABSTRACT
%
%
\begin{abstract}

Software deployment and updates are timely issue


In this thesis Butterknife, a
\acrshort{btrfs} snapshot based
provisioning suite is presented.

\end{abstract}

\chapter*{Acknowledgements}

I would like to thank my examiner \emph{Dr. Jim Dowling} and my supervisor \emph{Lars Kroll} firstly for providing me with the opportunity to carry out this research and secondly for guiding me through it, as well.

Furthermore, I wish to thank \emph{Kalle Kebbinau} for providing a constant
stream of valuable input and feedback on my work and ideas.
I'd like to thank \acrshort{btrfs} community for merging the patches and being helpful overall.

I'd also like to thank international Free and Open-Source Software community
for the immense pool of freely available components that made it possible
to learn and build anything imaginable.

\clearpage
\tableofcontents*
\mainmatter
\pagestyle{newchap}
\clearpage

%
%
% INTRODUCTION
%
%

\chapter{Introduction}
\label{chap:intro}

Linux is an operating system kernel
developed by Linus Torvalds \cite{linux-a-portable-operating-system}
and initially released in 1991.
Linux in conjunction with userspace utilities
such as GNU \cite{free-software-free-society} is also known as GNU/Linux.
Linux-based operating systems are widely used in servers.
Linux-based Android exceeded 85% smartphone
market share in 2014
\cite{android-market-share}.
Even though Ubuntu has managed to gain some market share
Windows continues to be dominant operating system for desktops
and laptops next to steadily increasing Mac OS X
\cite{desktop-market-share}.

Up to now Linux-based operating system deployment has been
error prone, time-consuming process and usually specific to
a particular distribution of Linux.
Linux-based operating systems also have a long history
of being overly complex to set up for a novice computer user.
Even though Linux-based operating systems have made significant
progress on the servers
\footnote{Google and Amazon have successfully used open-source software
and commodity hardware to build enterprise grade cloud}
and embeddeded systems
\footnote{Android is the market leader in smartphones and it is composed of open-source components such as Linux},
the workstations and laptops have been left without attention.
%According to DistroWatch Ubuntu, ?? and ?? are the three most
%favored Linux distributions for end users.
In this paper technical solution to quickly
deploy Linux-based operating systems
and update software using
\acrshort{btrfs} filesystem snapshots is presented.

\section{Motivation}
\label{sec:mot}
The foundation of current work was established while author was setting up
the infrastructure to deploy Ubuntu 12.04 LTS on the PC-s of educational
institutions of Tallinn as part of the ongoing efforts of Tallinn Education
Department to switch from proprietary tools to open solutions
in order to avoid vendor lock-in.

Puppet was set up to manage Ubuntu workstations remotely. Local IT-support
took the role of bootstrapping the machines and joining them to remote
management server.

Customer A runs hundreds of embedded ARM computers for digital signage.
Software is currently updated by mailing the customer an SD-card with
updated software. The customer would prefer to update software and
media over the air but the software update atomicity has to be guaranteed
in order to avoid non-booting machines.

Customer B is about to deploy thousands of Ubuntu netbooks to be used as
remote workstations around the globe. It is vital to unroll security updates
as soon as possible, but at the same time it's necessary to guarantee
software update atomicity as the IT helpdesk is lacking in the remote
locations where the machines are used.
The solution has to be installable at customer premises and it
must make use of standard and recognized security methods.

Customer C has around thousand PC-s that need to be converted to Ubuntu,
but the budget is lacking and therefore manual labour has to be minimized.
Glitch-free software update mechanism is crucial part of minimizing manual
labour.

\section{Contributions}

The work produced a novel method of deploying and maintaining Linux
based workstations in an guaranteed and secure manner.

TODO

\section{Related Work}
\label{sec:related}

\subsection{Puppet and Foreman}

Puppet is a remote management system which features its own declarative
domain-specific language to describe the state of the configuration
\footnote{http://puppetlabs.com/}. Puppet server also known as Puppetmaster
hosts the configuration while managed machines run puppet agent which polls
the puppetmaster at specified interval, usually 30 minutes. Taken actions
are then reported back to the puppetmaster. Puppet agent and puppetmaster
both are written in Ruby and released the latest versions are released under
liberal Apache 2.0 license. Puppet can be used to manage both Linux and
Windows servers and workstations as well.

Puppet uses TLS based security model:
Puppetmaster maintains a certificate authority which is used
to sign certificate requests submitted by clients.
Fully qualified hostname is used to identify nodes and
it is also used derive common name for the X509 certificates.
Once a certificate is signed the nodes are expected to
execute whatever Puppetmaster dictates them to do.

Foreman is a complete lifecycle management software for physical and virtual
servers. Foreman incorporates Puppet, a custom web interface and provisioning
tools into single unified application. Even without using provisioning features
Foreman makes one of the most feature-complete web interfaces for Puppet
rivaling the Puppet Dashboard.

\subsection{Chef, Ansible and Salt}

Chef is infrastructure automation tool. Chef is written in Ruby and Erlang.
Chef uses domain-specific language written in Ruby.
Chef server stores your recipes as well as other configuration data.
The Chef client is installed on each server, virtual machine, container
or networking device or generally speaking node.
The client periodically polls Chef server latest policy and
state of the network. If anything on the node is out of date,
the client brings it up to date \cite{linuxmag-7841}.

\footnote{\url{https://www.chef.io/chef/}}.

Ansible remote management software uses \acrfull{ssh} to connect to the nodes which
means there is no agent running on the managed machine, this however makes
it slightly more complicated to use Ansible to manage machines behind NAT.
Ansible is written in Python and it uses state-driven resource
written in YAML.

Salt is an open-source configuration management system,
capable of maintaining remote nodes in defined states and
a distributed remote execution system used to execute commands
on remote nodes, either individually or by arbitrary selection criteria
\footnote{\url{http://docs.saltstack.com/en/latest/topics/}}.
Salt is developed by SaltStack which sells services around Salt.
Salt uses ZeroMQ to transfer data between Salt server and
Salt minions.
Currently alternative transport
RAET (Reliable Asynchronous Event Transport)
is in development and it is designed Salt in mind.
RAET attempts to address more complex message routing
schemes which are not possible with ZeroMQ \cite{raet}.


\subsection{Fully Automated Installation}

\acrfull{fai} is a non-interactive system to install, customize and manage
Linux systems and software configurations on computers as well as
virtual machines and chroot environments, from small networks to
large-scale infrastructures like clusters and cloud environments.
It's a tool for unattended mass deployment of Linux. The systems
are installed, and completely configured to your exact needs,
without any interaction necessary \cite{fai}.

\subsection{Clonezilla, Symantec Ghost, Acronis True Image}

Clonezilla \cite{clonezilla}
combines various open-source tools into a single cloning suite.
Clonezilla uses partclone utilities \cite{partclone} to
identify and transfer only used blocks of various filesystems, most notably
\acrshort{ntfs}, \acrshort{ext4} and \acrshort{btrfs}.
Clonezilla supports resizing filesystems after the clone
in order to make use of the whole disk space available
in the target machine.
This makes it possible to use same prepared image for disks of
various size, the template image has to be of course smaller
than the target machine disks.
Clonezilla supports most Windows and Linux filesystems.

Symantec Ghost, previously known as Norton Ghost is a corresponding commericial
product currently available on the market
\footnote{http://www.symantec.com/ghost-solution-suite/}
offered by Symantec Corporation.
Acronis True Image
\footnote{http://www.acronis.com/en-eu/personal/pc-backup/}
by Acronis International GmbH
is another similar product which supports Windows
and Mac OS X operating systems.

The fact that machines need to be taken offline is the main
drawback of classic disk cloning methods.

\subsection{FSArchiver}

FSArchiver
is a tool very much similar to Clonezilla,
but instead of storing disk image on a block level the
contents are stored on object-level (file, directory).
All filesystem attributes are preserved for Linux filesystems,
NTFS support is still experimental.
For archiving the filesystem has to be unmounted or mounted
read-only. Read-write mounted filesystems can be snapshotted 
with the assistance of LVM and archived afterwards
\cite{fsarchiver}.


\subsection{BSD Jails, Solaris Zones, OpenVZ, Linux Containers, systemd-nspawn}

Jails have been available in FreeBSD since version 4.x. Jails use chroot
syscall to substitute root filesystem of a process making it possible to
create a restricted environment which is isolated from the rest of the
operating system
\cite{jail}.

Solaris Zones were introduced few years later adding similar
capabilities to Solaris operating system.
Solaris Zones took advantage of \acrshort{zfs} filesystem making it
possible to snapshot and clone zones.

Linux has included chroot for long time as it's essential feature for switching from initial root filesystem (initramfs/initrd) to actual root filesystem.
Many network services take advantage of chroot syscall to confine
itself to a particular directory in order to mitigate consequences
of vulnerabilities and exploits.

The main issue with chroot is that dependencies of the target
application have to be available in the chroot root filesystem.
For instance a Python application which has modules loaded before
chroot operation could operate without any files in the chroot,
but shell script which relies on several executables need to have
those utilities available in chroot as well.
With copy-on-write and de-duplicating filesystems such as
\acrshort{btrfs} and
\acrshort{zfs} the problem how ever becomes irrelevant as root
filesystem of the chroots can be duplicated with no significant overhead.



\acrfull{lxc}
\footnote{\url{https://linuxcontainers.org/}}
takes advantage of the \emph{chroot} syscall and
recently Linux \emph{cgroups} (control groups subsystem) which permit
more  operating system level virtualization.
Control groups are used to implement limiting, accounting
and isolation of CPU, memory, disk I/O, network, etc resource usage.
\acrshort{lxc} allows various backing stores, most notably \acrshort{zfs}, \acrshort{btrfs} and
OverlayFS which make it very easy to enable container
snapshotting and streaming backups.

Controversial systemd now includes \lstinline!systemd-nspawn!
which can be used to start up a container using kernel namespaces
very much like \acrshort{lxc} does. Another utility \lstinline!machinectl!
can be used to manage the containers.
\cite{systemd-nspawn}

\subsection{Docker and Rocket}

Docker started off as a way to automate container deployment and
configuration using containers and control groups present in Linux
kernel. As Docker started to add features that CoreOS developers
deemed excessive an alternative project Rocket was founded
\cite{rocket}.
Rocket aims
As Amazon also announced EC2 Container Service,
Rockets plan to formalize the container standard
makes it possible have various implementations while
maintaining cross-vendor compatibility.

\subsection{CoreOS and Ubuntu Core}

CoreOS \footnote{https://coreos.com/} is a rearchitected Linux
distribution which provides minimalist foundation to run Docker containers.
It uses two-partition scheme to provide atomic updates of the root
filesystem. The operating system runs off a read-only filesystem
while the other one can be patched runtime. Reboot or \emph{kexec}
can be used to boot into the updated system. This prevents rendering
device unbootable due to interrupted upgrade.

Ubuntu Core is an Ubuntu flavour tailored towards Internet of Things
and as a container platform. Ubuntu Core introduced root filesystem
transactional updates to Ubuntu using Snappy
\footnote{http://developer.ubuntu.com/en/snappy/}.
Ubuntu Core is designed to run Docker applications and can be used.
Snappy is also plays important role in Ubuntu Phone ecosystem.
Snappy uses OverlayFS (?) to implement transactional updates.

Snappy applications use directory based namespacing
and a Snappy application in essence is a tarball of a version
of an application \cite{ubuntu}.


\subsection{OverlayFS}

OverlayFS is a feature introduced in Linux 3.18 which makes it
possible to merge contents of two separate mountpoints on the fly \cite{overlayfs}.
OpenWrt uses OverlayFS to implement writable JFFS2 layer on top of
read-only SquashFS filesystem.

\subsection{LVM, mdadm and dmraid}

\acrshort{ext4} has been primary filesystem for Linux based workstations and
servers for a while. It provides filesystem primitives such as files,
directories, permissions and timestamping.
In order to add redundancy
either software \acrfull{raid} or \acrfull{lvm} can be used.

Software RAID is implemented in Linux by means of \emph{mdadm}.
Software RAID can be used to build RAID1, RAID0, RAID10/01, RAID5
or RAID6 arrays without dedicated RAID controller which could also
impose a vendor lock-in.

LVM enables pooling of drives, mirroring and snapshotting by adding
an abstraction layer on top of physcal disks. Any filesystem that
can be deployed on physical disk can also be deployed on top of
LVM's logical volume. The kernel takes care of mapping logical
addresses to corresponding disk's physical address.
The snapshotting feature of LVM however has been claimed to be buggy.
\cite{fedora-and-lvm}


\subsection{Btrfs and ZFS}

\acrshort{btrfs} and \acrfull{zfs} both are modern copy on write filesystems
which also fill in the role of volume manager
\cite{btrfs-the-linux-b-tree-filesystem}
\cite{chris-mason-the-btrfs-filesystem}.
\acrshort{btrfs} has been claimed to be unstable but the situation has
improved significantly over the past year or two.
Facebook has been testing \acrshort{btrfs} in production since the April of 2014.
\cite{btrfs-production-users}
Chris Mason, a lead developer of \acrshort{btrfs} joined Facebook
in the end of 2013 with the goal of improving \acrshort{btrfs} support
for enterprise applications.
\cite{leaving-fusionio}

\acrshort{btrfs} supports redundancy in RAID0/1/10 configurations and
RAID5/6 support was added with Linux 3.19 \cite{btrfs-for-3.19}.
\acrshort{btrfs} supports zlib and lzo compression algorithms,
however enabling compression for \acrshort{btrfs} is known to
seriously hamper performance of database engines.

\acrshort{btrfs} supports subvolumes, which makes it possible to group
directories and files into logical units.
As mentioned above, \acrshort{lxc} makes use of subvolumes
by confining the root filesystem to a \acrshort{btrfs} subvolume
if \acrshort{btrfs} backing store is used.
This means that root filesystem of a container
can easily be snapshotted.

In \acrshort{btrfs} context snapshotting is actually
a generalization of subvolume cloning,
thus \emph{subvolume}, \emph{clone} and \emph{snapshot} may be used
interchangeably in certain contexts.
Due to copy-on-write architecture subsequent writes
to the original subvolume do not affect
the subvolume clone and there is no performance
degradation for the original subvolume.

\acrshort{btrfs} permits transmitting filesystem data over the network
by a concept of \emph{btrfs send} and \emph{btrfs receive}.
\acrshort{btrfs} send mandates the subvolume to be in a read-only mode,
which means that \emph{btrfs subvol snapshot} has to be issued
with extra \emph{-r} flag.


\acrshort{btrfs} uses \emph{received\_uuid} and \emph{uuid} to
identify snapshots for transfer.
The \emph{received\_uuid} corresponds to the \emph{uuid} on
the initial machine and it remains intact for any subsequent transfers.
For differential snapshots few extra steps are taken.
During snapshot send an optimal parent snapshot is
identified and that is used as basis for the differential snapshot.
On the receiving end the a read-write snapshot of the parent
snapshot is created and filesystem operations
are replayed on the subvolume.
Finally corresponding \emph{received\_uuid} is set and
system call is issued to set subvolume read-only.


\acrfull{grub}
is the main bootloader used
by Linux-based operating systems on x86 and PowerPC based machines.
Earlier versions of GRUB supported multi-stage booting process,
which meant that GRUB stage1 binary was embedded in the
\acrfull{mbr} which loaded stage1.5 embedded
32256 byte area between the \acrshort{mbr} and first partition.
The stage1.5 contained filesystem drivers which could
address the filesystem contents and boot stage2 from
the \emph{/boot/grub} of the Linux filesystem.
\cite{grub2-fails-to-install}

GRUB2 dropped support for multi-stage booting process,
instead it is recommends that the first partition
starts at megabyte boundary, leaving
more than 500kB room between MBR
and first partition which is well enough to accommodate
feature-rich bootloader.
GRUB2 added support for booting from \acrshort{btrfs} root filesystem
in various configurations
hence in order to boot from
\acrshort{btrfs} a GRUB2 installation is required and older versions of
GRUB are not supported.
GRUB2 also now supports booting from a particular subvolume,
making it possible to place several root filesystems
in same \acrshort{btrfs} pool.
\cite{does-grub-support-btrfs}

Debian introduced \acrshort{btrfs} with Squeeze and has improved support
since then \cite{debian-btrfs}.
Ubuntu also has supported \acrshort{btrfs} for a while with customized
subvolume naming scheme:
root filesystem is placed in subvolume named \emph{@}
and home directories in a subvolume called \emph{@home}.

\subsection{apt-btrfs-snapshot and yum-fs-snapshot}

In Ubuntu package repositories there is available
\lstinline!apt-btrfs-snapshot!
\footnote{https://launchpad.net/apt-btrfs-snapshot}
package,
which creates snapshot of the root filesystem subvolume \emph{@}
before every \lstinline!apt-get! operation.

\lstinline!yum-plugin-fs-snapshot!
\footnote{\url{http://man7.org/linux/man-pages/man1/yum-fs-snapshot.1.html}}
is the corresponding package for Fedora and
Red Hat based distributions.


These approaches make it possible to boot into previous snapshots
in case there are issues with the updated packages.

\subsection{FreeNAS, Rockstor and OpenMediaVault}

FreeNAS is a FreeBSD \cite{freenas}
based distribution which builds a complete NAS solution on top of
ZFS filesystem and web interface.
Rockstor is a complementary CentOS 7 based solution that uses \acrshort{btrfs} instead
of \acrshort{zfs} filesystem \cite{rockstor}.
OpenMediaVault provides similar functionality using Debian Wheezy
instead of CentOS \cite{openmediavault}.
All three of them support \acrshort{smb}/\acrshort{cifs} (Windows file shares),
\acrshort{nfs} (UNIX file shares) and filesystem aided snapshots.


\subsection{rsync and rsnapshot}

rsync is an open source utility designed for
fast incremental file transfer.
It is most commonly invoked with archiving flag (-a) which
retains permissions, ownership, timestamps and symlinks.
In that case files are transferred only if
modified timestamp or file length differs.

rsnapshot is an utility that takes advantage of hardlinking
functionality of \acrshort{ext4} and other similar filesystems.
By creating a clone of a directory tree using hardlinks no
extra disk space is consumed. Applying classical rsync on top of
the clone only increments by the disk usage of changed files.


\subsection{OpenWrt and DD-WRT}

Most Linux based open-source router firmwares originate from
Linksys WRT54G wireless router.
Initially Cisco did not provide source code for the router as GPL mandates.
Between 2003-2008 Free Software Foundation attempted to cooperate
with Cisco to work out issues, but as Cisco continued to release
new devices with similar issues Free Software Foundation eventually
sued Cisco for malpractice.
After the lawsuit Cisco complied and has been releasing firmware
sources for all of their devices which make use of software
released under GPL licenses
\cite{fsf-vs-cisco}.
Linksys WRT54G sources were basis for various Linux distributions for routers such as
DD-WRT \cite{dd-wrt},
Tomato \cite{tomato}
OpenWrt \cite{openwrt}.

OpenWrt as we know it today is a Linux distribution for embedded devices
which attempts to provide writable filesystem and package management.
OpenWrt supported hardware list mainly targets routers, but other devices are
listed as well \cite{openwrt-toh}. OpenWrt can be used to
extend lifetime of equipment that otherwise would be largely obsolete due
to unmaintained software from hardware manufacturer.

Most high-end consumer grade routeres employ 8MB NOR Flash chip which is
directly connected to the \acrshort{soc} without controller
\cite{openwrt-flash-layout}.
The Flash storage is usually partitioned at least as 3 slices:
bootloader, read-only root filesystem, read-write overlay.

The read-only root filesystem contains SquashFS
\footnote{http://squashfs.sourceforge.net/}
which is highly-efficient compressed read-only filesystem that
supports variety of compression algorithms.
The read-write overlay partition
is formatted as JFFS2 (journalling flash filesystem).

This method makes it possible to: perform factory reset simply by
formatting the JFFS2 partition and upgrading firmware by overwriting
SquashFS partition. Due to lack of redundancy in consumer-grade routers
an interrupted firmware upgrade usually renders device unfit for use
\cite{building-murphy-compatible-embedded-linux-systems}
\cite{safe-upgrade-of-embedded-systems}.
This is also known as \emph{bricking} in embedded developer jargon.


\cite{software-update-scheme-by-airwaves}

\subsection{Android}

Android ROM images are typically distributed as zip files which contain
binary blobs for modem and bootloader in addition to snapshots of the
file primary filesystems of Android: boot, cache, recovery, system and
userdata
\footnote{https://dl.google.com/dl/android/aosp/shamu-lrx22c-factory-ff173fc6.tgz}.
Differential images are also available, in that case zip file contains
directory tree of files intended to be overwritten or added to the original
root filesystem and post-installation scripts which correct the file permissions
\footnote{http://gapps.itvends.com/gapps-lp-20141212-signed.zip}.

ROM manager such as ClockworkMod \cite{clockworkmod} or
TWRP \cite{twrp} has to be used to install or patch
third-party ROM-s.
An alternative Fastboot method is also present in most
Android devices and it can be used to directly write raw filesystem images and
unlock the device
\cite{fastboot}.
CyanogenMod is an aftermarket software for phones that are not
supported by the manufacturer anymore and it can
be installed with TWRP or ClockworkMod.
ClockworkMod and TWRP both can be used to download
images in the zip format and then
automatically reboot to the recovery mode to install the
ROM or updates.
Similar methods are provided by some of the hardware
vendors to update the ROM over the air.
As Android is open-source vendors tend to customize various aspects
of the software update process, there is no single canonical
way to update Android devices.



\subsection{OpenStack}

OpenStack is a free and open-source cloud computing software platform
which is composed of several components of which most noteworthy for current work are:
Glance image service, Ironic bare metal provisioning,
Swift object storage and Cinder block storage.
Glance provides discovery, registery and retrieval services of virtual machine images
\cite{glance}.
Glance BitTorrent delivery enables BitTorrent support for transferring the images
\cite{glance-bittorrent-delivery}.

Glance supports variety of disk formats \cite{glance-formats}:

\begin{itemize}
\item VHD disk format, a common disk format used by virtual machine monitors from VMWare, Xen, Microsoft, VirtualBox, and others
\item VMDK disk format supported by many common virtual machine monitors
\item VDI disk format supported by VirtualBox virtual machine monitor and the QEMU emulator
\item ISO archive format used by optical disks eg CD-ROM
\item QCOW2 disk format supported by the QEMU emulator that can expand dynamically and supports Copy on Write
\item AMI disk format used for Amazon machine images.
\end{itemize}

\noindent

As of February 2015 Glance work has started to add
\acrfull{ova} and \acrfull{ovf}
\cite{ovas-and-ovfs-what-are-they-and-whats-the-difference}
support.
The Glance \acrshort{api} does not however address versioning
of disk and container images, therefore differential
updates of images are also not implemented.


%
%
% BACKGROUND
%
%

\chapter{Background}
\label{chap:bgr}

\section{Initial task}

The initial task was to use Ubuntu as operating system basis
for schools due to rich set of both open-source and
proprietary software components available in Ubuntu ecosystem.

So far the machine deployment has been a tedious task involving
manual labour:
The Ubuntu 14.04 LTS image had to be downloaded from the Internet
and transferred to a memory stick.
The Ubuntu installer was booted from the memory stick
and usual installation was performed which took roughly 20 minutes.
The machine was booted into Ubuntu,
Puppet was installed on the machine and Puppet configuration
was tweaked to use our server.
This took another 10 minutes and was not a procedure that could
be performed by a novice user using (pseudo-)graphical user interface.
Once the certificates was signed on the Puppetmaster the
machine downloaded necessary packages and applied configuration
changes.
Usually this would take several Puppet runs and as a result
setting up a classroom of computers took several days
depending on the command-line proficiency of local
IT-support, which in some cases was close to zero.

In earlier phases of the project remastered Ubuntu 12.04
was used to bootstrap the machines, but as the
packages were constantly updated in the Ubuntu repositories,
the CD generation process was complex, time-consuming and
error-prone this approach was eventually given up
and vanilla Ubuntu was used instead.


\section{Problems with package management}

Ubuntu uses APT (Advanced Packaging Tool) as basis for
it's package management.
APT was originally developed as part of Debian operating system
to be used as \emph{dpkg} frontend.
While \emph{dpkg} can be used to install and remove packages,
it does not provide dependency tracking nor fetching
packages from remote locations which are implemented by APT.
APT significantly simplifies the installation of software
components by downloading packages from different sources
and checking package dependencies prior installation.

Ubuntu Software Center builds another abstraction on top of APT,
while hiding libraries and other system components it enables
even more simplified installation of apps for Ubuntu based
machines as shown in Figure~\ref{fig:ubuntu-software-center}.
For remotely managed machines the Ubuntu Software Center
and other graphical package management tools were removed.

\begin{figure}[tbhp]
  \centering
  \includegraphics[width=\textwidth]{images/ubuntu-software-center.png}
  \caption{Ubuntu software center}
  \label{fig:ubuntu-software-center}
\end{figure}

There are however certain corner-cases where APT may render
the package management unusable.
For instance package list corruption was faced on several occasions,
in that case APT crashes with segmentation fault
\cite{apt-segfault}
and currently the only known solution to the problem
involves deleting package lists and running \lstinline!apt-get update! again.
Several faulty packaging scripts were stumbled on,
for example it was not possible to remove certain versions of LibreOffice packages
and manual intervention was necessary
\cite{upgrading-libreoffice}.

Debian community has been working hard to provide differential updates for
the packages, but as of February 2015 the efforts have proven fruitless.
Differential updates are applied for package lists
\cite{avoiding-slow-package-updates},
but binary diffs for packages have not implemented yet.
Fedora community has however successfully deployed differential packages
\cite{fedora-presto},
thus reducing the amount of data needed to be transferred during an package update.
For bigger software (eg LibreOffice) the lack of differential
updates poses a serious concern, especially for low-bandwidth links.
Puppet, SaltStack, Chef, Ansible and other traditional configuration
management fit best the scenario where each node has slightly different
configuration and it makes sense to keep them separate. However
provisioning very similar nodes with for instance Foreman has obvious
overhead -- each node has to fetch updated packages independently from
the same APT repositories, same has to be done for application software.

Release upgrades for example from Ubuntu 12.04 to Ubuntu 14.04
have proven to be especially troublesome due to the fact that system libraries
and files are being replaced and interrupted release upgrade may leave system
in an unusable state.

As it has hopefully become clear by now
installation of software for Ubuntu and Debian
is most usually performed using APT in one form or another.
Software that is not available in an APT repository
is troublesome to install.
For instance Smarttech distributes software for their smart
whiteboard products as a .zip of Debian packages.
Similarily Canon printer drivers are available as a .zip file.
Last version of Acrobat Reader is also not available
from any APT repository for Ubuntu 14.04.
Skype distributes a Debian package for Ubuntu, but again
not from a APT repository.
Setting up an APT repository is not a trivial task,
even for an experienced Linux sysadmin.


For classroom deployment cloning has been used in the past:
Windows, Ubuntu or both are installed on a physical template machine.
Template machine is thoroughly tested.
Tools such as Clonezilla \cite{clonezilla} or Symantec Ghost are used to transfer the
harddisk image to the other machines.
As the whole procedure is a complex undertaking
it is usually performed once a year in summer especially for
educational institutions.
In fact cloning was used by some of the participating
schools -- for example Alan Õis, the IT-support at Mustamäe Gümnaasium
used Clonezilla to set up his classrooms.



%\begin{figure}[!htb]
%\centering
%\scalebox{0.5}{\input{dia/traditional-partitioning.tex}}
%\caption{Partitioning with separate /home}
%\label{fig:traditional-partitioning}
%\end{figure}

%Even so separate filesystem for home directories
%as described in Figure~\ref{fig:traditional-partitioning} has
%proven to be effective method against wiping the whole disk
%during reinstall of Ubuntu.

\section{Specification}

Considering the needs of the commercial customers and
experience gained in the first iteration of the migration project
following list of requirements were derived for next iteration.

Firstly the solution has to support all major Linux distributions
-- Ubuntu, Fedora, Red Hat, etc.
The software upgrades have to be atomic, in other words
interrupted updates can not render a workstation unusable.
Software upgrades must retain domain join without having
to join machine to a domain.
The home directories must remain intact during software updates.
It has to be possible to perform provisioning stage
from \acrfull{pxe},
off bootable USB memory sticks and optionally CD-R discs.


It has to be possible to run a central server for all nodes.
It has to be possible to run a local instance.
Push and pull capabilities to transfer templates between servers.

Following requirements were specified for security:
As initial provisioning can be assumed to be done on premises,
man-in-the-middle attacks can be ruled out in that
provisioning stage.
It has to be possible to verify subsequent incremental snapshots by means of asymmetric keys.
Consistent methods for root filesystem template fingerprinting have to be provided

%
%
% DESIGN
%
%
\chapter{Butterknife Design and Architecture}
\label{chap:design}
We have outlined a number of existing methods and tools
which address various aspect of Linux deployment on workstations
in chapter \ref{chap:intro}, and it has hopefully become clear
the functionality and guarantees provided by the presented systems.
However, it is clear that there will never be a single tool
that is optimal for every application.

Yet, many problems are a shared concern between all of these systems.
Foremost among these are \emph{bootstrapping}, i.e. getting
the initial software setup on the machine,
\emph{upgrading}, that is updating the software components on the machine and
\emph{configuring} the software components.

To address this issue, we present \emph{Butterknife},
a provisioning suite that provides solutions for bootstrapping and
upgrading Linux-based workstations, while remaining flexible enough
to be used to deploy any Linux-based operating system
and to be used in conjunction with already existing
configuration management tools such as Puppet and Salt.
Butterknife brings additional value to already existing
ecosystem and bridges gap between remastered installation medium
(eg Estobuntu) and Puppet managed machines.

\section{Concepts}
\label{sec:concepts}

The prototype draws inspiration from embedded computers
where certain guarantees have to be provided.
Butterknife in it's current form makes use of \acrshort{btrfs}
filesystem and Linux Containers.
Current architecture of Butterknife provides
atomic updates of root filesystem.

The template preparation workflow for
Ubuntu based distribution and Puppet based configuration
management is shown in
Figure~\ref{fig:template-preparation-workflow}:
\acrshort{lxc} is used to bootstrap a container,
\lstinline!apt-get update! is used to update package lists,
\lstinline!puppet apply! is used to apply configuration on the container,
\lstinline!apt-get upgrade! is used to upgrade the packages and
\lstinline!apt-get autoremove! is used to remove packages that
were installed as dependencies
for packages removed by Puppet.
Finally \lstinline!butterknife lxc release! is used to stop
the container and create a snapshot of the root filesystem of the container.
For subsequent releases the cycle starts again with \lstinline!apt-get update!.
The Butterknife does not confine user to Puppet or Ubuntu,
\acrshort{lxc} supports a variety of distributions and scripts for
Salt persistence are included in the template overlay
directory of Butterknife Git repository.

\begin{figure}[!htb]
\centering
\scalebox{0.6}{\input{dia/template-preparation-workflow.tex}}
\caption{Template preparation workflow using Butterknife}
\label{fig:template-preparation-workflow}
\end{figure}

The deployment workflow of the prototype is split into
bootstrap and live stages as shown in
Figure~\ref{fig:butterknife-workflow}.
The template prepared in the template preparation workflow
is served by \lstinline!butterknife serve!.
Provisioning image is booted either via
\acrfull{pxe} or from USB memory stick.
Provisioning utility
partitions the target machine storage device,
creates \acrshort{btrfs} filesystem and
transfers full snapshot of the template via \acrfull{http}.
Target subvolume is mounted at \lstinline!/mnt/target!
and post-installation tasks, for example
bootloader installation, are performed.

Finally the provisioning utility reboots the machine
and system boots from the newly received subvolume.
Butterknife DBus service starts up and
connects to the Butterknife server waiting for
subsequent snapshots.
Once new snapshots are available,
DBus service fetches the differential snapshots and
adds them to the \acrshort{btrfs} pool.
Snapshot is optionally verified and post-installation
scripts are executed.
User is notified about requirement to reboot the
machine to new snapshot via the DBus notification service.
For subsequent snapshots the cycle repeats.


\begin{figure}[!htb]
\centering
\scalebox{0.6}{\input{dia/workflow.tex}}
\caption{Butterknife deployment workflow}
\label{fig:butterknife-workflow}
\end{figure}



\noindent Butterknife consists of four major components:

\begin{enumerate}
\item Template helpers
\item Command-line utility.
\item Buildroot based provisioning image.
\item DBus services for applying incremental snapshots online.
\end{enumerate}


%
%
% IMPLEMENTATION
%
%
\chapter{Implementation}
\label{chap:impl}



\section{Template helpers}

\acrshort{lxc} containers are used to bootstrap the template for provisioning.
Creating container with \acrshort{btrfs} backing store (lxc-create -B btrfs)
on top of a \acrshort{btrfs} filesystem places the container in an
isolated subvolume which makes it easy to snapshot the container.
Within the container \emph{puppet apply} and similar methods can be used
to take advantage of already existing configuration management know-how.
Otherwise traditional manual labour can be employed
to set up the template: installing packages, tweaking configuration files etc.

During the release phase the \acrshort{lxc} container is stopped,
pre-release scripts placed under \lstinline!/etc/butterknife/pre-deploy.d!
are executed to clean up package cache and temporary files.
Then a read-only \acrshort{btrfs} snapshot is generated from the container root filesystem.
At this point new snapshot becomes available via running instance of
\lstinline!butterknife serve!
Post-deploy scripts are placed under \lstinline!/etc/butterknife/post-deploy.d!.


\section{Command-line utility}

The command-line utility is mainly targeted for
advanced use-cases:
pushing-pulling snapshots via \acrfull{ssh},
pulling snapshots via HTTP(S) or multicast,
serving snapshots via \acrshort{http} or multicast.
The utility also provides interfacing with
\acrshort{lxc} to prepare the templates and
support for systemd-nspawn
is planned \cite{systemd-nspawn}.


The Python programming is done in object-oriented manner,
thus adding additional transport methods is trivial.
Falcon \acrshort{http} \acrshort{api} framework
\footnote{\url{http://falconframework.org/}}
from Rackspace was used to build the
\acrshort{http} \acrshort{api} portion of the Butterknife to serve
snapshots over \acrshort{http}.
The \acrshort{http} \acrshort{api} serves information about templates
available in the server's \emph{/var/butterknife/pool}.
The \acrshort{api} exposes several methods for iterating
over templates and subvolumes present in
the server's \acrshort{btrfs} pool.

The \emph{name} of a template follows naming scheme of DBus objects
incorporating fully qualified domain name in reverse and the identifier
of the object.
The \emph{version} refers to the snapshot of the template.
The \emph{arch} refers to target architecture which is normalized
to \emph{x86} for 32-bit and \emph{x86\_64} for 64-bit Intel x86 machines.
For example the \acrshort{btrfs} subvolume stream URL for
snap42 of the 32-bit
\lstinline!EduWorkstation that originates from butterknife.koodur.com! would be

\emph{/api/template/com.koodur.butterknife.EduWorkstation/arch/x86/version/snap42/stream}.

Note that the stream URL also accepts parent argument,
so incremental snapshot can be received simply by appending
\emph{?parent=snap41}.
The unicast snapshot transfer topology is
shown in Figure~\ref{fig:butterknife-usecase-http}.
Note that unicast suffers obvious scalability issue,
the uplink of the server is eventually congested and
throughput per node decreases with every additional node.

\begin{figure}[!htb]
\centering
\scalebox{0.5}{\input{dia/butterknife-usecase-http.tex}}
\caption{Deployment over \acrshort{http}}
\label{fig:butterknife-usecase-http}
\end{figure}

Multicast is used to resolve the scalability issue of
the initial provisioning stage.
Snapshot transfer topology with off-site
server is shown in Figure~\ref{fig:butterknife-usecase-tee}.
In this case the snapshot is transferred over \acrshort{http} from
the server by one of the participating nodes.
That node proxies the stream to local LAN segment using multicast.
All the other nodes are receiving over multicast

\begin{figure}[!htb]
\centering
\scalebox{0.5}{\input{dia/butterknife-usecase-tee.tex}}
\caption{Deployment over \acrshort{http} and multicast}
\label{fig:butterknife-usecase-tee}
\end{figure}

Alternatively snapshots can be pulled either over \acrshort{http} or \acrshort{ssh} from
the server to a local machine and served from there over multicast
as shown in Figure~\ref{fig:butterknife-usecase-multicast}.

\begin{figure}[!htb]
\centering
\scalebox{0.5}{\input{dia/butterknife-usecase-multicast.tex}}
\caption{Deployment in local network segment over multicast}
\label{fig:butterknife-usecase-multicast}
\end{figure}



\section{Provisioning image}

The provisioning image was designed to bootstrap a machine.
Debian, Ubuntu, Gentoo and Buildroot were evaluated as
provisioning platforms.
With Debian and Ubuntu the resulting PXE bootable
image would have exceeded 100MB, as the image
is uncompressed to RAM, booting on machines with
less than 1GB of RAM is troublesome.
As of February of 2015 the CoreOS image suffers similar issue -
\emph{vmlinuz}
\footnote{\url{http://stable.release.core-os.net/amd64-usr/current/coreos_production_pxe.vmlinuz}}
and
\emph{initrd}
\footnote{\url{http://stable.release.core-os.net/amd64-usr/current/coreos_production_pxe_image.cpio.gz}}
files required to boot over PXE are correspondingly 24MB and 117MB.
With Gentoo significant tweaking was required, because Gentoo is
mainly targeted for power users.
Buildroot
an embedded Linux system build system
was eventually used to generate an (<15MB)
all-in-one PXE-bootable image as well as ISO image
which can be dumped on a USB memory stick \cite{tools-for-embedded-linux-dev}.

Using Python to build pseudo-graphic menu-driven user interface was
evaluated and deemed not necessary for the goal as Python runtime and
dependant libraries add about 10MB to the resulting image.
Additionally \lstinline!parted! Python bindings were unavailable
in Buildroot package selection.
Instead \lstinline!dialog! in conjunction with
\lstinline!curl!, \lstinline!jq! and others were used to build the user-interface
and shell was used to program the user-interface logic.
Resizing of NTFS filesystems is provided by \lstinline!ntrfsresize! utility
which is part of \lstinline!ntfs-3g! package, this eases deployment of
dual-boot machines.
Complete multicast is supported via consistent snapshot naming scheme
and \lstinline!udpcast-receive! and \lstinline!udpcast-sender! utilities which
are part of \lstinline!udpcast! package.

The security model for the initial deployment phase could be improved
as only method of verification of the source is the certificate
authority chain verified by \emph{curl} during the \acrshort{btrfs} snapshot
retrieval. For multicast transfers there is no security
enforced by software, it is assumed that multicast is used only
in protected LAN segments.

The used partitioning scheme is described in Figure~\ref{fig:pooled-partitioning}
is inspired by Ubuntu and Lennart Poettering's article.
\cite{revisiting-how-we-put-together-linux-systems}
The whole block device is allocated to single \acrshort{btrfs} filesystem
which is mounted at \lstinline!/var/butterknife/pool! making
it possible to easily iterate over templates and root filesystem instances
present in the machine.
Whenever a \acrshort{btrfs} (differential) snapshot stream is received
the incoming subvolume is placed under \lstinline!/var/butterknife/pool!.
Before transfer remnants of previously interrupted transfers are cleaned
up by simply iterating over directories beginning with \lstinline!@template:!
and attempting to create a file inside the directory.
If the file creation succeeds, the subvolume is deleted.
Note that prior successful exit \lstinline!btrfs receive! sets the
subvolume read-only, thus file creation should fail.

Once the template subvolume is successfully received
a read-write clone is made with \lstinline!@root:! prefix,
this signifies an \emph{instance} of a root filesystem.
The instance subvolume is mounted at \lstinline!/mnt/target!
and several mountpoints such as \lstinline!/dev/!,
\lstinline!/proc/!, \lstinline!/sys/! are bound to \lstinline!/mnt/target!.

Finally \lstinline!chroot! is issued to enter the instance to
run \lstinline!butterknife-postdeploy! which executes
post-deploy scripts which are part of the template.
Most usually the \acrshort{btrfs} pool is mounted at \lstinline!/var/butterknife/pool!
of the instance and \lstinline!@persistent! subvolume is created
in the pool.
The persistent subvolume is then mounted at \lstinline!/var/butterknife/persistent!.
The persistent subvolume is used to retain hostname,
domain join information (Kerberos keytab, Samba secrets),
Puppet keys and certificates etc.
Final aspect of the postdeploy scripts is the
bootloader installation.
As the root filesystem is esentially swapped out,
\lstinline!grub-install! is required to update references
to the newly created OS instance.

\begin{figure}[!htb]
\centering
\scalebox{0.5}{\input{dia/pooled-partitioning.tex}}
\caption{Pooled partitioning}
\label{fig:pooled-partitioning}
\end{figure}


\section{DBus services}

For running nodes a DBus service was written to poll the snapshot server
for updates and another DBus service was written in Python to notify user
about available updates.

\section{Btrfs receive parent subvolume lookup issues}

As of kernel 3.17 there is no consistent way of transferring
differential snapshots in a distributed Git-like fashion due to way
\lstinline!btrfs receive! locates the parent subvolume.
Whenever \lstinline!btrfs send! is issued, the \emph{uuid} of origin
subvolume is bundled with the bitstream, that becomes
the \emph{received\_uuid} on the receiving endpoint and
new \emph{uuid} is assigned for the created subvolume.
For incremental snapshots \lstinline!btrfs send! also bundles
the \lstinline!uuid! of the parent subvolume,
now \lstinline!btrfs receive! attempts to locate the parent
subvolume by \emph{received\_uuid} of local subvolumes.

This effectively restricts the workflow to one direction
as shown in Figure~\ref{fig:btrfs-received-uuid-issue}.
In other words if a full snapshot is transferred
from machine A to B and B to C, then it is impossible
to apply incremental snapshots from A to C, because
\lstinline!btrfs receive! is unable to locate the snapshot
to be used as parent.
This prevents running a downstream Butterknife server and
even more importantly it makes tricky restoring snapshot
in scenarios where \acrshort{btrfs} is used for backuping.

\begin{figure}[!htb]
\centering
\scalebox{0.5}{\input{dia/btrfs-received-uuid-issue.tex}}
\caption{\lstinline!received_uuid! inconsistency}
\label{fig:btrfs-received-uuid-issue}
\end{figure}

Arne Jansen, previously a \acrshort{btrfs} developer maintains far-progs repository
\cite{far-progs},
which contains tools for manipulating \acrshort{btrfs} snapshot streams,
this format is also known as FAR (Filesystem ARchive).
The \lstinline!btrfs-receive! from \lstinline!far-progs! features
two extra flags: \lstinline!-p! which disables
automatic parent searching and allows user to specify which
subvolume to use as a parent and \lstinline!-d! which
allows specifying a custom subvolume name.
Disabling parent search makes it possible to detach
\acrshort{btrfs}' UUID mechanism and customize the differential snapshot logic.
In this case care must be taken of snapshot consistency,
applying differential snapshot on incorrect parent subvolume
may cause data corruption or end up with a crash
of \lstinline!btrfs receive!.
The changes were isolated by the author and
submitted to \lstinline!btrfs-progs! upstream
\footnote{
[PATCH] btrfs-progs: receive explicit parent support
\url{http://www.mail-archive.com/linux-btrfs@vger.kernel.org/msg43329.html}}.

Note that current \lstinline!btrfs receive! approach does not provide
any verification of the resulting snapshot and the unique
identifiers are simply used to look up the parent subvolume.
Thus disabling automatic parent search and
using the Butterknife provided logic
is not necessarily inferior method.

In fact far-progs repository contains \lstinline!fssum!
utility which can be used to checksum a directory tree.
It checks both -- file contents and attributes,
including permissions and modification times.
This information could be for example signed by GPG
in the developer machine and


\section{Btrfs receive confinement}

As said, \acrshort{btrfs} is an evolving filesystem and there
are corner-cases where \acrshort{btrfs} fails security-wise.
For example issuing \lstinline!btrfs subvol list! within
a \lstinline!chroot! exposes subvolumes outside the new root filesystem.

For Butterknife usecase other security aspects have to be considered.
As of \emph{btrfs-progs} version 3.19 the \lstinline!btrfs send!
emits simply a stream of encoded opcodes
which are intended to be replayed by \lstinline!btrfs receive!
\footnote{\url{http://git.kernel.org/cgit/linux/kernel/git/kdave/btrfs-progs.git/tree/cmds-receive.c?h=v3.19.x\#n792}}:
create subvolume, snapshot parent subvolume,
create file, \emph{mkdir}, \emph{mknod}, \emph{mkfifo}, symlink,
\emph{link}, \emph{unlink}, \emph{rename}, \emph{rmdir}, open file,
close file, write to file, set/remove extended attributes,
truncate file, \emph{chmod}, \emph{chown}.

In case of full snapshot system call is issued to
create empty subvolume with specified name and
in case of differential snapshot an system call is issued
to locate parent subvolume by UUID and clone it.
After the initial opcode traditional filesystem
operations are carried out on the newly
created/cloned subvolume.

As can be seen in the \lstinline!unlink! opcode
implementation on line 456 of cmds-receive.c
\footnote{\url{http://git.kernel.org/cgit/linux/kernel/git/kdave/btrfs-progs.git/tree/cmds-receive.c?h=v3.19.x\#n456}},
the \lstinline!path_cat! function is used to concatenate
path of the subvolume and target filename.
Investigating further reveals that no sanitization is performed on the path
\footnote{\url{http://git.kernel.org/cgit/linux/kernel/git/kdave/btrfs-progs.git/tree/send-utils.c?h=v3.19.x\#n711}}, leaving receiving end vulnerable to path traversal attacks.
Carefully crafted \acrshort{btrfs} stream could for example delete files
of the running operating system rendering the whole system
in unusable state, or even worse substitute for example
Puppet configuration and certificate authority file in the
Butterknife persistent subvolume making it possible for a third party
to gain access over the machine.

Several \lstinline!btrfs-progs! patches were submitted to improve
the security of \lstinline!btrfs receive!.
Patch to enforce \lstinline!chroot!
before parsing the \acrshort{btrfs} stream was accepted upstream
\footnote{
[PATCH] btrfs-progs: enforce chroot for btrfs receive
\url{https://www.mail-archive.com/linux-btrfs@vger.kernel.org/msg43019.html}}.
This patch however confines the \lstinline!btrfs receive!
process only to the parent directory of the newly created subvolume,
making it possible to attack other subvolumes contained in the same directory.
The confinement could be improved even more, for example
by parsing the first opcode, performing either
subvolume creation or parent subvolume cloning,
then issuing \lstinline!chroot! to the subvolume directory
and finally replaying the remaining opcodes.
This would, of course make it troublesome to receive multiple
snapshots in the same stream, as it is possible via \lstinline!-e!
flag of \lstinline!btrfs send!.



%
%
% EVALUATION
%
%
\chapter{Experimental Evaluation}
\label{chap:evaluation}
In order to show that our basic approach in Butterknife is practical and
and extendible for large-scale applications such as unrolling
updates for workstations, netbooks, smartphones,
automotive applications or other embedded devices
an experimental evaluation was carried out on the prototype.

\section{Feedback from service users}

Butterknife service users, local IT-support in this case
were generally satisfied with the delivery.
Reinstallation of classroom or conversion to dual-boot,
wasn't anymore necessarily a task that had to
be strictly scheduled for school holidays.
Butterknife-based upgrade from Ubuntu 12.04 to
Ubuntu 14.04 was performed within first
half of a day at Mahtra.

\section{Feedback from project users}

Butterknife project users, fellow devops in this case
were also positively surprised by the
streamlined deployment process of Butterknife.

Butterknife omits the overhead
and complexity associated with traditional
ISO remastering systems such as \emph{remastersys}
\cite{livecd-customization}
making it possible for virtually anyone
to roll a customized distribution
for particular purpose.

Butterknife also makes it easier to
bundle proprietary components
into the template, thus setting up APT repository to distribute
packages for the targets is not necessary.


\section{Performance}

The resulting full snapshot for schools was based on 32-bit Ubuntu 14.04 and
it included MATE 1.8.2 desktop environment, Mozilla Firefox 37 web browser,
LibreOffice 4.4.2 office suite,
VLC 2.1.6 multimedia player,
Skype 4.3.0 voice over IP solution,
Inkscape 0.48.4 scalable vector graphics editor,
Gimp 2.8.10 photo editor and many tweaks
to make the system usable in Estonian schools.

The throughput of the server-client channel depends on
several factors:
raw snapshot bitstream size,
network bandwidth;
compression algorithm;
parallelization of compression;
encryption;
storage medium.

The disk usage of resulting
\lstinline{@template:com.koodur.butterknife.EduWorkstation:x86:snap83}
subvolume was approximately 6.20GiB
due to fragmentation and holes in sparse files.
Issuing \lstinline{btrfs send} on the subvolume
results in approximately 5.75GiB bitstream.
Compressing the bitstream yields different
results depending on the compression algorithm as
shown in Figure~\ref{chart:resulting-file-size}.

\begin{figure}
\begin{tikzpicture}
    \begin{axis}[xbar,width=12cm, height=7cm,
        xmin=0,
        symbolic y coords={xz, bzip2, gzip, lz4 -9, lz4 -1, raw},
        nodes near coords, nodes near coords align={horizontal},
        ytick=data]
        \addplot coordinates {
            (5.75,raw)
            (3.21,lz4 -1)
            (2.77,lz4 -9)
            (2.51,gzip)
            (2.32,bzip2)
            (1.87,xz)
        };
    \end{axis}
\end{tikzpicture}
\caption{Resulting file size (GB)}
\label{chart:resulting-file-size}
\end{figure}

Note that streaming compression is necessary for scenarios
where differential snapshots are not stored as static files
or where the full snapshots are directly served from
\lstinline!btrfs send! which is also the default case for Butterknife.
Direct streaming with \lstinline!btrfs send! makes it possible
to take full advantage of the copy-on-write filesystem
and snapshots while keeping disk usage on the server side minimal.

Various compression tools were benchmarked with
the raw \acrshort{btrfs} stream stored in RAM.
The time shown in Figure~\ref{fig:compression-benchmark-real-time}
was measured on Intel(R) Core(TM) i7-4770R quad-core CPU
clocked at 3.20GHz with 2x 8GB DDR3 memory modules running
Ubuntu 14.04 LTS and 3.16.0 kernel.
%Similar tests were performed on QNAP TS-451 NAS-box equipped with
%Intel Celeron J1800 dual-core CPU and 2x 4GB DDR3 memory modules.
The source and destination directories were
mounted as \lstinline!tmpfs! on the same
machine to exclude the
HDD/SDD and network effects on the test.
In addition to single-threaded \lstinline!gzip!
the parallel version of \lstinline!gzip! algorithm,
\lstinline!pigz! is included in the results as well as \lstinline!pxz!
the parallel version of \lstinline!xz!.
\\

\begin{figure}
\begin{tikzpicture}
    \begin{axis}[xbar,width=12cm, height=6cm,
        xmin=0,
        symbolic y coords={xz, bzip2, pxz, gzip, pigz},
        nodes near coords, nodes near coords align={horizontal},
        ytick=data]
        \addplot coordinates {
            (46,pigz)
            (206,gzip)
            (494,pxz)
            (555,bzip2)
            (2150,xz)
        };
    \end{axis}
\end{tikzpicture}
\caption{Real time (sec)}
\label{fig:compression-benchmark-real-time}
\end{figure}

Note that \lstinline!pxz! actually used 53m41.214s of CPU time
and \lstinline!pigz! used 5m31.287s of CPU time.

As root filesystem contains numerous small files significant
slowdown was imminent if spinning disk was used on the either side.
An average throughput of ~37MB/s was observed while
running \lstinline!btrfs send! from or \lstinline!btrfs receive! to
Western Digital WD40EFRX without using encryption or compression
over plain \acrshort{http}.
Using arbitrary SSD-s on both ends averaged around 100MB/s
due to gigabit ethernet used for benchmarking.

SSD-s however face other issues

\begin{figure}
\begin{tikzpicture}
    \begin{axis}[xbar,width=8cm, height=14cm,
        xmin=0,
        symbolic y coords={xz on i7-4770R, Fast Ethernet, bzip2 on i7-4770R, pxz on i7-4770R, gzip on Celeron-J1800, gzip on i7-4770R, btrfs receive on Samsung M9T, pigz on Celeron-J1800, btrfs send on WD10JFCX, btrfs receive on WD10JFCX, btrfs send on WD40EFRX, btrfs send on SDSSDHP256G, Gigabit Ethernet, btrfs send on SSDMCEAW240A4, pigz on i7-4770R},
        nodes near coords, nodes near coords align={horizontal},
        ytick=data]
        \addplot coordinates {
            (125,pigz on i7-4770R)
            (112,btrfs send on SSDMCEAW240A4)
            (100,Gigabit Ethernet)
            (86.2,btrfs send on SDSSDHP256G)
            (58,btrfs send on WD40EFRX)
            (47,btrfs receive on WD10JFCX)
            (41,btrfs send on WD10JFCX)
            (29.9,pigz on Celeron-J1800)
            (27,btrfs receive on Samsung M9T)
            (27,gzip on i7-4770R)
            (16.8,gzip on Celeron-J1800)
            (11.6,pxz on i7-4770R)
            (10.3,bzip2 on i7-4770R)
            (10,Fast Ethernet)
            (2.6,xz on i7-4770R)
        };

    \end{axis}
\end{tikzpicture}
\caption{Average throughput (MB/s)}
\label{fig:average-throughput}
\end{figure}

The empiric observations carried out with
the snap83 of the root filesystem as shown in Figure~\ref{fig:average-throughput} pointed out
the bottlenecks that previously went unnoticed.
The most important conclusion that can be drawn from the
results is that enabling compression may actually hamper the
deployment speed.
Single-threaded \lstinline!gzip! might make sense for 100MBps infrastructure,
but going beyond gigabit threshold the law of diminishing returns can be observed.
Additionally the harddisks with spinning platters
impose limitations caused by prolonged seek times.
Even with solid-state disks effects of normal filesystem fragmentation
can be observed.
The compression aspect is notable because
Estonian Educational Network has scheduled infrastructure
upgrades for 2016 and their plan is to supply
gigabit link to every educational institution of Estonia.



\section{Integrity}

It must not be forgotten that \acrshort{btrfs} is relatively
new filesystem and even though on-disk format of
\acrshort{btrfs} is not excpected to change anymore
the kernel drivers and userspace utilities are
still being actively developed.
Due to this there are certain corner-cases where
\acrshort{btrfs} may fail horribly,
for example 3.14 and earlier kernel had often issues
with filesystem corruption and data loss
\cite{btrfs-corruption},
especially when filesystem was running out of free space.
The author hasn't faced any serious issues with
3.16 kernel, but for example btrfs-progs 3.16 have
bugs which prevent it's use in case of nested subvolumes.
Ubuntu also has upgraded from 3.14 to 3.16 in Ubuntu 14.04,
their last Long Term Support release.
Linux 3.18 has also proven to be reliable when in comes
to \acrshort{btrfs}, but for example Linux 3.19 faces
a deadlock during an attempt to mount
dirty \acrshort{btrfs} filesystem
\cite{btrfs-dirty-mount-deadlock}.


%
%
% CONCLUSIONS
%
%

\chapter{Conclusions and Future Work}
\label{chap:conc}


\section{Conclusions}

The implementation satisfies, exceeds to be precise,
the requirements of educational institutions.
It significantly decreases local IT-support work,
by reducing workstation bootstrap down to 15 minutes even for
a regular sized classroom.
With the addition of push/pull capabilities
Butterknife is also becoming attractive tool
for devops who need to move around Linux containers.
The addition of explicit parent flag (\lstinline!-p!) on
the receiving end also makes it easy to
restore backups.

Source code of the solution was published at GitHub.
\footnote{GitHub: Butterknife provisioning suite \url{https://github.com/v6sa/butterknife/}}
The instructions for setting up similar infrastructure
are provided at GitHub and are constantly being improved.

\section{Verification}

Currently there is no method for verifying the integrity
of received snapshot, the transport channel security
(\acrshort{tls}, \acrshort{ssh}) is the only method against man-in-the-middle attacks.
There are plans to make use of \emph{fssum} to generate
manifest of the snapshot directory tree and
sign the file with GPG on the developer machine.
Hardware tokens (Estonian ID-card, Ubikey etc) can be used
to add extra security layers.

An extra command \emph{verify} for
\emph{butterknife} utility will be added
to generate manifest on the receiving end and
to compare it's contents agains the signed manifest.
The manifest comparison time can be reduced by
parsing verbose output of \lstinline!btrfs receive!
to determine modified files
in case of differential snapshots.
Signature and querying method has to be designed.

\section{systemd-nspawn support}

Currently LXC is the only supported template preparation method.
Debian 8 codenamed \emph{jessie} was released in the April of 2015
with a new default init system \emph{systemd}
\cite{debian-jessie-released}.
Ubuntu 15.04 released few days earlier also
ships with \emph{systemd} by default
\cite{ubuntu-vivid-vervet-released}.

With UBun

\section{BitTorrent integration}

Currently only HTTP(S), multicast and their combinations are supported
for initial provisioning stage.
Multicast is designed for usecases where simultaneous
control over multiple machines is possible.
The differential snapshots are primarily downloaded
via HTTP(S) because coordinating multicast
transfers with roaming laptops is a complex scenario.
Optionally push/pull can be performed over \acrshort{ssh}
making Butterknife already now very flexible tool.

BitTorrent is a \acrfull{p2p} file sharing protocol
designed by Bram Cohen \cite{incentives-build-robustness-in-bittorrent}.
BitTorrent is designed to facilitate file transfers among multiple peers
across unreliable networks.
It has potential to offload content transfer to nodes
participating in the network as shown in
Figure~\ref{fig:butterknife-usecase-bittorrent}.
In this section two viable approaches are discussed.

\begin{figure}[!htb]
\centering
\scalebox{0.5}{\input{dia/butterknife-usecase-bittorrent.tex}}
\caption{Possible load distribution scenario using BitTorrent}
\label{fig:butterknife-usecase-bittorrent}
\end{figure}


As getting consistent output from \lstinline!btrfs send!
is tricky it makes sense to store the snapshot
bitstreams as files and use BitTorrent to redistribute them.
This way \lstinline!received_uuid! can be kept in sync with the origin.
Similarily each incremental snapshot can be stored on the
disk and distributed as torrents.
As full snapshots are large and consume a lot
of disk space it makes sense for example
keep every 100th full snapshot and apply
incremental snapshots one by one to get
to a desired snapshot.
The main advantage of such approach is the overhead:
in addition to \acrshort{btrfs} filesystem which already
contains all the necessary snapshots,
full and incremental snapshot bitstreams
are stored as separate files.
Additionally the step-by-step incremental
snapshot approach defeats the whole
purpose of using filesystem such as \acrshort{btrfs}.

Second approach dives into the BitTorrent specifics.
A .torrent file contains metadata about the content in question and a
tracker URL -- that is the service which is used to discover other peers in the
pool of participating nodes also known as swarm.
BitTorrent splits files into pieces and SHA-1 hash is calculated per piece.
BitTorrent protocol does not specify minimal piece length
\cite{bep0003},
but for example libtorrent imposes restriction of having piece length
a multiple of 16KB
\cite{libtorrent-create-torrents}.
It is reccommended to keep BitTorrent file size below 100kB,
which means the piece size is correlated to content size.
\cite{torrent-piece-size}.


For multi-file torrents the files in the directory tree are handled
as a continuous stream of data of the concatenated files
as shown in Figure~\ref{fig:torrent-multifile},
thus changing size of a file that happens to be placed in the beginning of a torrent
file results in completely different checksums for the whole torrent.
Such approach is reasonable for rarely changing data, but for current usecase
causes significant overhead.

\begin{figure}[!htb]
\centering
\scalebox{0.35}{\input{dia/torrent-multifile.tex}}
\caption{Multi-file torrent handles directory tree as a continous stream of data}
\label{fig:torrent-multifile}
\end{figure}

BitComet has implemented \emph{Align File to Piece Boundary} function
\cite{bitcomet-align-to-piece},
which adds a padding file if necessary to align files to piece boundary
as shown in Figure~\ref{fig:torrent-multifile-aligned}.
This way pieces which contain identical files retain same piece checksums,
however small files add significant overhead due to padding files.
Compression of pieces sent on the wire has been proposed
\cite{bittorrent-wishlist}.
This could resolve the overhead issue introduced due to padding files.
The problem of piece alignment could also be addressed
simply by introducing new file mode.

\begin{figure}[!htb]
\centering
\scalebox{0.35}{\input{dia/torrent-multifile-aligned.tex}}
\caption{Align File to Piece Boundary}
\label{fig:torrent-multifile-aligned}
\end{figure}


\acrshort{btrfs} uses \acrshort{crc32c} for checksumming and support for additional
checksum algorithms, namely \acrshort{sha1} is planned
\footnote{\url{https://btrfs.wiki.kernel.org/index.php/Project_ideas\#More_checksumming_algorithms}}.
Current on-disk format supports up to 256-bit hash checksum per
metadata block and arbitrary count of hashes for per-block checksums.
\footnote{\url{https://btrfs.wiki.kernel.org/index.php/FAQ\#What_checksum_function_does_Btrfs_use.3F}}
As of November 2013 \acrshort{btrfs} defaults to 16kB or page size
whichever is larger.
On most Linux workstation page size is set to 4kB, thus 16kB block
size takes precedence.
\footnote{\url{https://git.kernel.org/cgit/linux/kernel/git/mason/btrfs-progs.git/commit/?id=c652e4efb8e2dd76ef1627d8cd649c6af5905902}}.

As online deduplication is in works for \acrshort{btrfs} it makes sense to
combine the two, implementing additional system call for \acrshort{btrfs} in
order to perform block lookup by checksum is trivial task.
This could make it possible to implement high-performance
BitTorrent implementation which takes advantage of \acrshort{btrfs} metadata.

Aligned checksumming would permit sharing platform-independent
(images; fontconfig cache; dconf database; LaTeX packages;
Bash, Python, Ruby, Perl, Lua, Java source and bytecode)
file chunks between machines of different architecture (amd64, i386, armel, armhf)
from arbitrary snapshots.

Generating .torrent corresponding to a root filesystem
has other issues as well.
Piece size of 16kB results in a torrent file
exceeding 10MB for Ubuntu root filesystem and that didn't even
include padding files required to align piece boundary to file beginning.
Most BitTorrent client implementations fail to handle .torrent
files of such size resulting in out of memory errors or freezes.
Also BitTorrent currently does not handle symlinks,
POSIX filesystem permissions and access control lists
\cite{posix-acl}.

This leads us to believe that these properties be transferred
using additional manifest file generated by eg \lstinline!fssum!,
making use of .torrent file redundant.
In fact Google Summer of Code 2015 project
\cite{btrfs-content-storage-mode}
was submitted by
Carnegie Mellon University graduate student Harshad Shirwadkar
to implement content based storage in \acrshort{btrfs}
\footnote{\url{https://btrfs.wiki.kernel.org/index.php/Project_ideas\#Content_based_storage}}.

Bram Cohen, the BitTorrent creator filed patent for
live streaming version of BitTorrent
\cite{bittorrent-live} which promises
latency of few seconds opposed to previously available approaches
which exceeded latency of several magnitudes higher.
The technology will be available free of charge for users as well as
content distributors. Patent will be used to enforce
the quality of the available software so
for example client applications of bad quality would not
degrade the performance of the technology.
BitTorrent Live could be used to synchronize several clients
to apply differential snapshot from same parents to same target snapshots
and use BitTorrent Live simply as transport protocol.



\section{Alternative filesystem layouts}

Lennart Poettering, an controversial Free Software developer has outlined a method
of building Linux based systems using \acrshort{btrfs} snapshots
\cite{revisiting-how-we-put-together-linux-systems}.
The new layout splits high level components of software
(operating system, desktop environment, frameworks, office suit)
into separate subvolumes which can be upgraded independently.
This requires significant effort from operating system distributors,
software suite vendors but promises significant save of effort on testing
software on Linux based systems.
Most notably a snapshot naming scheme is proposed in the article,
which would permit mixing operating system files with different
sets of libraries, frameworks and applications which
in fact was used to derive the Butterknife naming scheme.

Even though Ubuntu Snappy applications are simply tarballs,
the concept of separated namespaces is appearent there.



%
%
% APPENDIX
%
%

\appendix

\bibliography{references}

\twocolumn
\printglossaries
\onecolumn

\end{document}
